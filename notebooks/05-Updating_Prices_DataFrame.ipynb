{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:09:32.156174Z",
     "start_time": "2022-07-12T20:09:31.111009Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from yahooquery import Ticker\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "this_year = datetime.datetime.today().strftime('%Y')\n",
    "last_year = (datetime.datetime.now() - relativedelta(years=1)).strftime('%Y')\n",
    "two_years_ago = (datetime.datetime.now() - relativedelta(years=2)).strftime('%Y')\n",
    "today = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "one_year_ago = (datetime.datetime.today() - relativedelta(years=1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:09:32.171056Z",
     "start_time": "2022-07-12T20:09:32.158090Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding price history, current price and calculating KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:09:45.820397Z",
     "start_time": "2022-07-12T20:09:44.467067Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## adding price history by month and year\n",
    "\n",
    "\n",
    "hist_price = pd.read_csv('PRICES/monthly/todos_precos_montlhy_AV.csv', index_col=False,low_memory=False)\n",
    "\n",
    "hist_price['date'] = pd.to_datetime(hist_price['date'])\n",
    "\n",
    "hist_price['ano'] = hist_price['date'].dt.year\n",
    "hist_price['mês'] = hist_price['date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "lpp = hist_price.sort_values('date').groupby(['symbol','ano','mês']).tail(1)\n",
    "\n",
    "lpp.drop(lpp.columns.difference(['date','5. adjusted close','symbol','ano','mês']), \n",
    "         axis=1,inplace=True)\n",
    "\n",
    "lpp = lpp.drop(lpp[(lpp.ano == datetime.datetime.today().year) & (lpp[\"mês\"] == datetime.datetime.today().month)].index)\n",
    "\n",
    "pivall = pd.read_pickle('clean_data/pivoted_data/pivot_all_data.pkl')\n",
    "\n",
    "pivall_hist_prices = pivall.merge(lpp, left_on=['CODIGO','ano','mês'], right_on=['symbol','ano','mês'],\n",
    "                                  how='left')\n",
    "\n",
    "pivall_hist_prices.to_pickle('clean_data/pivoted_data/pivot_all_data_hist_prices.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "pivall_hist_prices.to_pickle('BACKUPS/pivoted_data/pivot_all_data_hist_prices%s.pkl'%today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:12:20.817195Z",
     "start_time": "2022-07-12T20:09:48.778257Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Reading current price from yahoo finance\n",
    "\n",
    "companies_data = pd.read_excel('info_brazilian_companies.xlsx')\n",
    "\n",
    "item_list = companies_data['CODIGO'].to_list()\n",
    "\n",
    "\n",
    "\n",
    "## getting currente prices\n",
    "\n",
    "current_prices = {}\n",
    "for item in item_list:\n",
    "    try:\n",
    "        item_1 = item.lower()\n",
    "        current_prices.update({item: Ticker('%s.sa'%item_1).price[item_1+'.sa']['regularMarketPrice']})\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "companies_curr_price = pd.DataFrame.from_dict(current_prices, orient='index', columns=['current_price'])\n",
    "companies_curr_price['current_price'] = np.select([companies_curr_price['current_price']== {}],[0],companies_curr_price['current_price'])\n",
    "companies_curr_price['current_price'] = companies_curr_price['current_price'].astype('float64')\n",
    "companies_curr_price.to_pickle('PRICES/current_prices.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "companies_curr_price.to_pickle('BACKUPS/price/current_prices%s.pkl'%today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:12:21.176261Z",
     "start_time": "2022-07-12T20:12:20.826192Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### adding current prices to dataframe on TTM row\n",
    "df_data = pd.read_pickle('clean_data/pivoted_data/pivot_all_data_hist_prices.pkl')\n",
    "companies_curr_price = pd.read_pickle('PRICES/current_prices.pkl')\n",
    "companies_curr_price['TTM'] = 'TTM' \n",
    "\n",
    "\n",
    "companies_curr_price.reset_index(inplace=True)\n",
    "\n",
    "df_data = df_data.merge(companies_curr_price,left_on=['CODIGO','LABEL'],right_on=['index','TTM'],how='outer')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_data['Preço'] = np.nan_to_num(df_data['5. adjusted close'])+np.nan_to_num(df_data['current_price'])\n",
    "\n",
    "df_data.drop(['current_price','symbol','5. adjusted close','TTM','date'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "df_data.to_pickle('clean_data/pivoted_data/pivot_alldata_with_curr_price.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "df_data.to_pickle('BACKUPS/pivoted_data/pivot_alldata_with_curr_price%s.csv'%today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:12:22.837516Z",
     "start_time": "2022-07-12T20:12:21.180256Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Calculating KPIs\n",
    "\n",
    "pivot_alldata = pd.read_pickle('clean_data/pivoted_data/pivot_alldata_with_curr_price.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Proventos    \n",
    "pivot_alldata['Proventos'] = np.nan_to_num(pivot_alldata['Dividendos'])+np.nan_to_num(pivot_alldata['Juros sobre o Capital Próprio'])\n",
    "pivot_alldata['Payout'] = (pivot_alldata['Proventos'])/(pivot_alldata['Lucro Atribuído a Controladores'])\n",
    "pivot_alldata['Proventos por ação'] = (pivot_alldata['Proventos'])/(pivot_alldata['Total Ações'])  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# operations\n",
    "pivot_alldata['Margem EBITDA'] = pivot_alldata['EBITDA']/pivot_alldata['Receita Líquida']\n",
    "pivot_alldata['Margem EBIT'] = pivot_alldata['EBIT']/pivot_alldata['Receita Líquida']\n",
    "pivot_alldata['Margem líquida'] = (pivot_alldata['Lucro Atribuído a Controladores'])/(pivot_alldata['Receita Líquida'])\n",
    "pivot_alldata['Margem bruta'] = (pivot_alldata['Resultado Bruto'])/(pivot_alldata['Receita Líquida'])\n",
    "pivot_alldata['Taxa efetiva de imposto'] = np.abs(pivot_alldata['Imposto']/pivot_alldata['EBIT'])\n",
    "pivot_alldata['EBIT(1-t)'] = pivot_alldata['EBIT']*(1-pivot_alldata['Taxa efetiva de imposto'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# divida e patrimonio\n",
    "pivot_alldata['Dívida Bruta'] = pivot_alldata['Dívida curto prazo']+pivot_alldata['Dívida longo prazo']\n",
    "pivot_alldata['Disponibilidade'] = pivot_alldata['Caixa e Equivalentes de Caixa']+pivot_alldata['Aplicações Financeiras']\n",
    "pivot_alldata['Dívida Líquida'] = pivot_alldata['Dívida Bruta']-pivot_alldata['Disponibilidade']\n",
    "pivot_alldata['Dív_Líq/EBIT'] = pivot_alldata['Dívida Líquida']/pivot_alldata['EBIT']\n",
    "pivot_alldata['Dív_Líq/PL'] = (pivot_alldata['Dívida Líquida'])/(pivot_alldata['Patrimônio Líquido Consolidado'])\n",
    "pivot_alldata['D/E'] = (pivot_alldata['Dívida Bruta'])/(pivot_alldata['Patrimônio Líquido Consolidado'])\n",
    "pivot_alldata['Capital Investido'] = (pivot_alldata['Dívida Bruta'])+(pivot_alldata['Patrimônio Líquido Consolidado'])\n",
    "pivot_alldata['Dívida/Capital_Inv'] = (pivot_alldata['Dívida Bruta'])/(pivot_alldata['Capital Investido'])\n",
    "pivot_alldata['Patrimônio/Capital_Inv'] = (pivot_alldata['Patrimônio Líquido Consolidado'])/(pivot_alldata['Capital Investido'])\n",
    "pivot_alldata['Endividamento Financeiro'] = (pivot_alldata['Dívida Bruta'])/(pivot_alldata['Ativo Total'])\n",
    "pivot_alldata['Endividamento Financeiro Curto Prazo'] = (pivot_alldata['Dívida curto prazo'])/(pivot_alldata['Ativo Total'])\n",
    "pivot_alldata['Dív_Líq/ebitda'] = (pivot_alldata['Dívida Líquida'])/(pivot_alldata['EBITDA'])  \n",
    "pivot_alldata['Dívida Líquida Anterior'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Dívida Líquida'].shift()\n",
    "pivot_alldata['PL Con Anterior'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Patrimônio Líquido Consolidado'].shift()\n",
    "pivot_alldata['PL + Dív_Líq_Ant'] = (pivot_alldata['PL Con Anterior'])+(pivot_alldata['Dívida Líquida Anterior'])  \n",
    "pivot_alldata['PL/Ativos'] = (pivot_alldata['Patrimônio Líquido Consolidado'])/(pivot_alldata['Ativo Total'])\n",
    "pivot_alldata['PL + Dív_Líq'] = (pivot_alldata['Patrimônio Líquido Consolidado'])+(pivot_alldata['Dívida Líquida']) \n",
    "\n",
    "\n",
    "\n",
    "# returns\n",
    "pivot_alldata['ROE'] = (pivot_alldata['Lucro Atribuído a Controladores'])/(pivot_alldata['PL Con Anterior'])\n",
    "pivot_alldata['Porcentagem Retida'] = 1-(pivot_alldata['Payout'])  \n",
    "pivot_alldata['Ativo Total Anterior'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Ativo Total'].shift()\n",
    "pivot_alldata['ROA'] = (pivot_alldata['EBIT(1-t)'])/(pivot_alldata['Ativo Total Anterior'])        \n",
    "pivot_alldata['ROIC']=pivot_alldata['EBIT(1-t)']/pivot_alldata['PL + Dív_Líq_Ant']\n",
    "\n",
    "\n",
    "## ajustando indicadores onde patrimonio liquido é negativo\n",
    "pivot_alldata['ROE'] = np.select([pivot_alldata['PL Con Anterior'] < 0],[np.nan],pivot_alldata['ROE'])\n",
    "pivot_alldata['ROIC'] = np.select([pivot_alldata['PL Con Anterior'] < 0],[np.nan],pivot_alldata['ROIC'])\n",
    "\n",
    "# ativos e passivos \n",
    "pivot_alldata['Passivo/Ativo'] = (pivot_alldata['Passivo Circulante']+pivot_alldata['Passivo Não Circulante'])/(pivot_alldata['Ativo Total'])  \n",
    "pivot_alldata['Líquidez Corrente'] = (pivot_alldata['Ativo Circulante'])/(pivot_alldata['Passivo Circulante'])  \n",
    "pivot_alldata['Giro dos Ativos'] = (pivot_alldata['Receita Líquida'])/(pivot_alldata['Ativo Total'])  \n",
    "\n",
    "\n",
    "# capex\n",
    "pivot_alldata['Depreciação'] = np.abs(pivot_alldata['Depreciação, Amortização e Exaustão'])\n",
    "\n",
    "pivot_alldata['Capex'] = np.abs(pivot_alldata['Capex'])\n",
    "\n",
    "pivot_alldata['Capex'] = np.select([pivot_alldata['Capex'].isna()],\n",
    "                                   [np.abs(pivot_alldata['Caixa Líquido Atividades de Investimento'])],\n",
    "                                   pivot_alldata['Capex'])\n",
    "\n",
    "pivot_alldata['Capex Líquido'] = np.abs(pivot_alldata['Capex'])-(pivot_alldata['Depreciação'])\n",
    "pivot_alldata['Ativo_Circ non-cash'] = (pivot_alldata['Ativo Circulante']-pivot_alldata['Caixa e Equivalentes de Caixa']-pivot_alldata['Aplicações Financeiras'])\n",
    "pivot_alldata['Passivo_Circ non-cash'] = (pivot_alldata['Passivo Circulante']-pivot_alldata['Dívida curto prazo'])\n",
    "pivot_alldata['Capital de Giro non-cash'] = (pivot_alldata['Ativo_Circ non-cash']-pivot_alldata['Passivo_Circ non-cash'])\n",
    "pivot_alldata['Capital de Giro non-cash anterior'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Capital de Giro non-cash'].shift()\n",
    "pivot_alldata['Variação Capital de Giro'] = (pivot_alldata['Capital de Giro non-cash']-pivot_alldata['Capital de Giro non-cash anterior'])                                      \n",
    "pivot_alldata['Capital_Giro/revenues'] = (pivot_alldata['Capital de Giro non-cash']/pivot_alldata['Receita Líquida'])                                       \n",
    "pivot_alldata['Patrimônio Reinvestido'] = (pivot_alldata['Capex Líquido'])+(pivot_alldata['Variação Capital de Giro'])\n",
    "pivot_alldata['Porcentagem Reinvestida'] = (pivot_alldata['Patrimônio Reinvestido'])/(pivot_alldata['EBIT(1-t)'])\n",
    "pivot_alldata['Receitas/Capital_Inv'] = (pivot_alldata['Receita Líquida'])/(pivot_alldata['PL + Dív_Líq'])\n",
    "pivot_alldata['Capex/Receita'] = np.abs(pivot_alldata['Capex'])/pivot_alldata['Receita Líquida']\n",
    "pivot_alldata['Capex/Depreciação'] = np.abs(pivot_alldata['Capex'])/pivot_alldata['Depreciação']\n",
    "pivot_alldata['Capex Líquido/Receita'] = pivot_alldata['Capex Líquido']/pivot_alldata['Receita Líquida']\n",
    "pivot_alldata['Capex Líquido/EBIT(1-t)'] = pivot_alldata['Capex Líquido']/pivot_alldata['EBIT(1-t)']\n",
    "\n",
    "\n",
    "# pivotando preços units, on, pn e calculando market cap hist\n",
    "\n",
    "prices_pivoted = pivot_alldata.pivot_table(columns=['CLASSE'], index=['Codigo_CVM','DT_FIM_EXERC'],values='Preço')\n",
    "\n",
    "pivot_alldata = pivot_alldata.merge(prices_pivoted, left_on=['Codigo_CVM','DT_FIM_EXERC'], right_index=True,how='outer',)\n",
    "\n",
    "units = {'TIET11': 5,\n",
    "         'ALUP11': 3,\n",
    "         'BIDI11': 3,\n",
    "         'BPAC11': 3,\n",
    "         'ENGI11': 5,\n",
    "         'KLBN11': 5,\n",
    "         'RNEW11': 3,\n",
    "         'SAPR11': 5,\n",
    "         'SANB11': 2,\n",
    "         'SULA11': 3,\n",
    "         'TAEE11': 3}\n",
    "\n",
    "\n",
    "qnt_units = pd.DataFrame.from_dict(units, orient='index',columns=['Qtde de ações UN'])\n",
    "\n",
    "pivot_alldata = pivot_alldata.merge(qnt_units, left_on=['CODIGO'], right_index=True, how='outer')\n",
    "\n",
    "pivot_alldata['Qtde de ações UN'] = pivot_alldata['Qtde de ações UN'].fillna(value=1)\n",
    "\n",
    "qnt_mv_value = {'TIET': 5,\n",
    "         'ALUP': 3,\n",
    "         'BIDI': 3,\n",
    "         'BPAC': 3,\n",
    "         'ENGI': 5,\n",
    "         'KLBN': 5,\n",
    "         'RNEW': 3,\n",
    "         'SAPR': 5,\n",
    "         'SANB': 2,\n",
    "         'SULA': 3,\n",
    "         'TAEE': 3}\n",
    "\n",
    "qnt_mv = pd.DataFrame.from_dict(qnt_mv_value, orient='index',columns=['Qtde de ações UNITS'])\n",
    "\n",
    "pivot_alldata = pivot_alldata.merge(qnt_mv, left_on=['CDO_STRIP'], right_index=True, how='outer')\n",
    "\n",
    "\n",
    "\n",
    "conditions = [pivot_alldata['UNT N2'] > 0]\n",
    "\n",
    "choices = [((pivot_alldata['UNT N2']/pivot_alldata['Qtde de ações UNITS'])*pivot_alldata['Total Ações'])]\n",
    "\n",
    "pivot_alldata['Valor de Mercado'] = np.select(conditions, choices, default=((np.nan_to_num(pivot_alldata['ON'])*np.nan_to_num(pivot_alldata['Total ON'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PN'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PNA'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PNB'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PNC'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PND'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PNE'])*np.nan_to_num(pivot_alldata['Total PN'])) +\n",
    "                                                                       (np.nan_to_num(pivot_alldata['PNF'])*np.nan_to_num(pivot_alldata['Total PN']))))\n",
    "\n",
    "\n",
    "\n",
    "conditions = [pivot_alldata['UNT'] > 0]\n",
    "\n",
    "choices = [((pivot_alldata['UNT']/pivot_alldata['Qtde de ações UNITS'])*pivot_alldata['Total Ações'])]\n",
    "\n",
    "pivot_alldata['Valor de Mercado'] = np.select(conditions, choices, pivot_alldata['Valor de Mercado'])\n",
    "\n",
    "\n",
    "\n",
    "# calculando indicadores historicos que dependem do market cap\n",
    "\n",
    "pivot_alldata['Valor de Firma'] = pivot_alldata['Valor de Mercado']+(pivot_alldata['Dívida Líquida'])\n",
    "pivot_alldata['EV/EBITDA'] = pivot_alldata['Valor de Firma']/(pivot_alldata['EBITDA'])\n",
    "pivot_alldata['EV/EBIT'] = pivot_alldata['Valor de Firma']/(pivot_alldata['EBIT'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dependentes do share outstanding\n",
    "pivot_alldata['LPA'] = (pivot_alldata['Qtde de ações UN']*pivot_alldata['Lucro Atribuído a Controladores'])/(pivot_alldata['Total Ações'])\n",
    "pivot_alldata['VPA'] = (pivot_alldata['Qtde de ações UN']*pivot_alldata['Patrimônio Líquido Consolidado'])/(pivot_alldata['Total Ações'])\n",
    "\n",
    "# indicadores de preço históricos\n",
    "\n",
    "pivot_alldata['P/L'] = pivot_alldata['Preço']/pivot_alldata['LPA']\n",
    "pivot_alldata['P/VPA'] = pivot_alldata['Preço']/pivot_alldata['VPA']\n",
    "pivot_alldata['P/EBITDA'] = (pivot_alldata['Preço']*pivot_alldata['Total Ações'])/(pivot_alldata['Qtde de ações UN']*pivot_alldata['EBITDA'])\n",
    "pivot_alldata['P/EBIT'] = (pivot_alldata['Preço']*pivot_alldata['Total Ações'])/(pivot_alldata['Qtde de ações UN']*pivot_alldata['EBIT'])\n",
    "pivot_alldata['P/Ativo'] = (pivot_alldata['Preço']*pivot_alldata['Total Ações'])/(pivot_alldata['Qtde de ações UN']*pivot_alldata['Ativo Total'])\n",
    "pivot_alldata['P/Cap_Giro'] = (pivot_alldata['Preço']*pivot_alldata['Total Ações'])/(pivot_alldata['Qtde de ações UN']*(pivot_alldata['Ativo Circulante']-pivot_alldata['Passivo Circulante']))\n",
    "pivot_alldata['P/Ativo_Circ_Líq'] = (pivot_alldata['Preço']*pivot_alldata['Total Ações'])/(pivot_alldata['Qtde de ações UN']*(pivot_alldata['Ativo Circulante']-pivot_alldata['Passivo Total']))\n",
    "\n",
    "\n",
    "\n",
    "# classficiação small/large caps\n",
    "\n",
    "conditions = [(pivot_alldata['Valor de Mercado'] == 0),(pivot_alldata['Valor de Mercado'] < 50000000), ((pivot_alldata['Valor de Mercado'] >= 50000000) & (pivot_alldata['Valor de Mercado'] < 300000000)),\n",
    "             ((pivot_alldata['Valor de Mercado'] >= 300000000) & (pivot_alldata['Valor de Mercado'] < 2000000000)), ((pivot_alldata['Valor de Mercado'] >= 2000000000) & (pivot_alldata['Valor de Mercado'] < 10000000000)),\n",
    "             ((pivot_alldata['Valor de Mercado'] >= 10000000000) & (pivot_alldata['Valor de Mercado'] < 200000000000)), (pivot_alldata['Valor de Mercado'] >= 200000000000)]\n",
    "\n",
    "choices = [np.nan,'Nano Cap','Micro Cap','Small Cap','Mid Cap','Large Cap','Mega Cap']\n",
    "\n",
    "pivot_alldata['Classificação Capitalização'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "\n",
    "\n",
    "# expected growths\n",
    "pivot_alldata['Crescimento esperado LPA'] = (pivot_alldata['Porcentagem Retida'])*(pivot_alldata['ROE'])     \n",
    "pivot_alldata['Crescimento esperado EBIT'] = (pivot_alldata['Porcentagem Reinvestida'])*(pivot_alldata['ROIC'])    \n",
    "pivot_alldata['Crescimento EBIT'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['EBIT'].pct_change()\n",
    "pivot_alldata['Crescimento Margem EBIT'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Margem EBIT'].pct_change()\n",
    "pivot_alldata['Crescimento LPA'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['LPA'].pct_change()\n",
    "pivot_alldata['Crescimento Receita'] = pivot_alldata.groupby(['CODIGO','tipo_resultado','trimestre'])['Receita Líquida'].pct_change()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "pivot_alldata = pivot_alldata.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "pivot_alldata.to_pickle('clean_data/pivoted_data/pivot_com_indicadores.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "pivot_alldata.to_pickle('BACKUPS/pivoted_data/pivot_com_indicadores%s.csv'%today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T20:12:24.041792Z",
     "start_time": "2022-07-12T20:12:22.839391Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## adding dividends and calculating dividend yield\n",
    "\n",
    "alldiv = pd.read_pickle('clean_data/dividends/proventos_b3.pkl')\n",
    "alldiv['Data COM'] = pd.to_datetime(alldiv['Data COM'])\n",
    "\n",
    "dv_year = alldiv.drop(alldiv.columns.difference(['Codigo_CVM','CLASSE','ano','Valor ajustado']),axis=1)\n",
    "\n",
    "dv_year = dv_year.groupby(['Codigo_CVM','CLASSE','ano'],as_index=False).sum()\n",
    "\n",
    "dv_year.rename({\"Valor ajustado\":\"Proventos no Período\",\"ano\":\"label\"},axis=1,inplace=True)\n",
    "\n",
    "dv_ttm = alldiv.drop(alldiv.columns.difference(['Codigo_CVM','CLASSE','Data COM','Valor ajustado']),axis=1)\n",
    "\n",
    "dv_ttm = dv_ttm.set_index('Data COM')\n",
    "\n",
    "dv_ttm = dv_ttm.loc[one_year_ago:today]\n",
    "\n",
    "dv_ttm = dv_ttm.groupby(['Codigo_CVM','CLASSE'],as_index=False).sum()\n",
    "\n",
    "dv_ttm.rename({'Valor ajustado':\"Proventos no Período\"},axis=1,inplace=True)\n",
    "\n",
    "dv_ttm['label'] = 'TTM'\n",
    "\n",
    "dv_all = pd.concat([dv_year,dv_ttm])\n",
    "\n",
    "df = pd.read_pickle('clean_data/pivoted_data/pivot_com_indicadores.pkl')\n",
    "\n",
    "df['Class div'] = np.select([((df['CLASSE']=='UNT') | (df['CLASSE']=='UNT N2'))],\n",
    "                           ['UNT'],df['CLASSE'])\n",
    "\n",
    "dv_all['label'] = dv_all['label'].astype(str)\n",
    "\n",
    "df['LABEL'] = df['LABEL'].astype(str)\n",
    "\n",
    "df_all = df.merge(dv_all,left_on=['Codigo_CVM','Class div','LABEL'],right_on=['Codigo_CVM','CLASSE','label'],\n",
    "                 how='left')\n",
    "\n",
    "\n",
    "df_all['Dividend Yield'] = df_all['Proventos no Período']/df_all['Preço']\n",
    "\n",
    "df_all.drop(['CLASSE_y','Class div', 'label'], axis=1,inplace=True)\n",
    "\n",
    "df_all = df_all.dropna(subset=['Nome_Empresarial'])\n",
    "\n",
    "df_all.to_pickle('clean_data/final_data/df_principal.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "df_all.to_pickle('BACKUPS/final_data/df_principal%s.pkl'%today)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Valuation KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:48:59.019797Z",
     "start_time": "2022-06-29T15:48:58.917999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"clean_data/final_data/df_principal.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:48:59.035679Z",
     "start_time": "2022-06-29T15:48:59.022175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttm = df.loc[df['LABEL'] == 'TTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:48:59.083371Z",
     "start_time": "2022-06-29T15:48:59.037674Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "damodaran_table = pd.read_excel('VALUATION/damodaran_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:48:59.115287Z",
     "start_time": "2022-06-29T15:48:59.085338Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# function to get spread and calculate cost of debt for company\n",
    "def cost_of_debt(brazil_risk_free_rate, interest_coverage_ratio):\n",
    "    if interest_coverage_ratio > 12.5:\n",
    "        #Rating is AAA\n",
    "        credit_spread = 0.0063\n",
    "    if (interest_coverage_ratio > 9.5) & (interest_coverage_ratio <= 12.5):\n",
    "        #Rating is AA\n",
    "        credit_spread = 0.0078\n",
    "    if (interest_coverage_ratio > 7.5) & (interest_coverage_ratio <= 9.5):\n",
    "        # Rating is A+\n",
    "        credit_spread = 0.0098\n",
    "    if (interest_coverage_ratio > 6) & (interest_coverage_ratio <= 7.5):\n",
    "        #Rating is A\n",
    "        credit_spread = 0.0108\n",
    "    if (interest_coverage_ratio > 4.5) & (interest_coverage_ratio <= 6):\n",
    "        # Rating is A-\n",
    "        credit_spread = 0.0122\n",
    "    if (interest_coverage_ratio > 4) & (interest_coverage_ratio <= 4.5):\n",
    "        #Rating is BBB\n",
    "        credit_spread = 0.0156\n",
    "    if (interest_coverage_ratio == 4):\n",
    "        # Rating is BB+\n",
    "        credit_spread = 0.02\n",
    "    if (interest_coverage_ratio > 3) & (interest_coverage_ratio < 4):\n",
    "        #Rating is BB\n",
    "        credit_spread = 0.0240\n",
    "    if (interest_coverage_ratio > 2.5) & (interest_coverage_ratio <= 3):\n",
    "        # Rating is B+\n",
    "        credit_spread = 0.0351\n",
    "    if (interest_coverage_ratio > 2) & (interest_coverage_ratio <= 2.5):\n",
    "        #Rating is B\n",
    "        credit_spread = 0.0421\n",
    "    if (interest_coverage_ratio > 1.5) & (interest_coverage_ratio <= 2):\n",
    "        # Rating is B-\n",
    "        credit_spread = 0.0515\n",
    "    if (interest_coverage_ratio > 1.25) & (interest_coverage_ratio <= 2):\n",
    "        #Rating is CCC\n",
    "        credit_spread = 0.0820\n",
    "    if (interest_coverage_ratio > 0.8) & (interest_coverage_ratio <= 1.25):\n",
    "        #Rating is CC\n",
    "        credit_spread = 0.0864\n",
    "    if (interest_coverage_ratio > 0.5) & (interest_coverage_ratio <= 0.8):\n",
    "        #Rating is C\n",
    "        credit_spread = 0.1134\n",
    "    if interest_coverage_ratio <= 0.5:\n",
    "        #Rating is D\n",
    "        credit_spread = 0.1512\n",
    "\n",
    "    cd = brazil_risk_free_rate + credit_spread\n",
    "\n",
    "    return cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:48:59.131396Z",
     "start_time": "2022-06-29T15:48:59.117254Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def busca_titulos_tesouro_direto():\n",
    "    url = 'https://www.tesourotransparente.gov.br/ckan/dataset/df56aa42-484a-4a59-8184-7676580c81e3/resource/796d2059-14e9-44e3-80c9-2d9e30b405c1/download/PrecoTaxaTesouroDireto.csv'\n",
    "    df = pd.read_csv(url, sep=';', decimal=',')\n",
    "    df['Data Vencimento'] = pd.to_datetime(\n",
    "        df['Data Vencimento'], dayfirst=True)\n",
    "    df['Data Base'] = pd.to_datetime(df['Data Base'], dayfirst=True)\n",
    "    multi_indice = pd.MultiIndex.from_frame(df.iloc[:, :3])\n",
    "    df = df.set_index(multi_indice).iloc[:, 3:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BRAZILIAN BOND 10 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:49:02.796013Z",
     "start_time": "2022-06-29T15:48:59.133210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "titulos = busca_titulos_tesouro_direto()\n",
    "\n",
    "# getting 10 year brazilian bond\n",
    "\n",
    "pre2031 = titulos.loc[('Tesouro Prefixado com Juros Semestrais', '2031-01-01')]\n",
    "bond = pre2031.iloc[-1]['Taxa Compra Manha']/100\n",
    "hoje = datetime.date.today()\n",
    "hoje_em_texto = '{}/{}/{}'.format(hoje.day, hoje.month, hoje.year)\n",
    "ontem = hoje - datetime.timedelta(days=4)\n",
    "ontem_em_texto = '{}/{}/{}'.format(ontem.day, ontem.month, ontem.year)\n",
    "#dez_ano = inv.get_bond_historical_data('Brazil 10Y', from_date=ontem_em_texto, to_date=hoje_em_texto)\n",
    "#brazil_10y_bond = dez_ano.iloc[-1]['Close']/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ERP, RISK FREE RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:49:02.811381Z",
     "start_time": "2022-06-29T15:49:02.797808Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting spread, risk free rate and erp\n",
    "\n",
    "brazil_default_spread = (damodaran_table.loc[damodaran_table['Country'] == 'Brazil']['Rating-based Default Spread'].values[0])/100\n",
    "brazil_risk_free_rate = bond-brazil_default_spread\n",
    "brazil_erp = (damodaran_table.loc[damodaran_table['Country'] == 'Brazil']['Total Equity Risk Premium'].values[0])/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## BETA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:29.605993Z",
     "start_time": "2022-06-29T15:49:02.812902Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### beta from yahoo\n",
    "\n",
    "companies = ttm['CODIGO'].unique()\n",
    "ttm['beta'] = np.nan\n",
    "\n",
    "for x in companies:\n",
    "    try:\n",
    "        y = x.lower()\n",
    "        beta = Ticker(y+'.sa').key_stats[y+'.sa']['beta']\n",
    "        ttm['beta'] = np.select([ttm['CODIGO'] == x],[beta],ttm['beta'])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "### SE ERRO beta médio do setor\n",
    "\n",
    "med = ttm.drop_duplicates('Nome_Empresarial',keep='first')\n",
    "\n",
    "mean = med.groupby('SEGMENTO')['beta'].mean()\n",
    "\n",
    "ttm['beta'] = np.select([ttm['beta'].isna()],[mean[ttm['SEGMENTO']]],ttm['beta'])\n",
    "\n",
    "### SE ERRO, beta médio global do damodaran\n",
    "\n",
    "mean_global = pd.read_excel('VALUATION/global_means_damodaran2021.xlsx')\n",
    "\n",
    "beta_glob = mean_global.groupby('Industry name')['Equity (Levered) Beta'].mean()\n",
    "\n",
    "ttm['beta'] = np.select([ttm['beta'].isna()],[beta_glob[ttm['DAMODARAN_GROUP']]],\n",
    "                        ttm['beta'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## COST OF EQUITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:29.637156Z",
     "start_time": "2022-06-29T15:51:29.607988Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cost_of_equity = brazil_risk_free_rate + beta*brazil_erp\n",
    "\n",
    "ttm['Cost of Equity'] = brazil_risk_free_rate+ttm['beta']*brazil_erp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## COST OF CAPITAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:29.669108Z",
     "start_time": "2022-06-29T15:51:29.641586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### INTEREST COVERAGE RATIO\n",
    "\n",
    "ttm['IC ratio'] = ttm['EBIT']/np.abs(ttm['Juros Pagos'])\n",
    "\n",
    "## you need to fin a better way to calculate the IC ratio\n",
    "ttm['IC ratio'] = np.select([ttm['IC ratio'].isna()],[3.5],ttm['IC ratio'] )\n",
    "\n",
    "### after tax cost of debt\n",
    "\n",
    "# after tax cost of debt\n",
    "\n",
    "ttm['Cost of Debt'] = ttm.apply(lambda row: cost_of_debt(brazil_risk_free_rate,row['IC ratio']), axis=1)\n",
    "\n",
    "\n",
    "ttm['After Taxes Cost of Debt'] = ttm['Cost of Debt']*(1-0.34)  ## brazilian marginal tax rate \n",
    "\n",
    "## COST OF CAPITAL\n",
    "\n",
    "ttm['Cost of Capital'] = (ttm['After Taxes Cost of Debt'] * ttm['Dívida/Capital_Inv'])+\\\n",
    "                        (ttm['Cost of Equity'] * ttm['Patrimônio/Capital_Inv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## EXPECTED GROWTH REVENUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:33.673439Z",
     "start_time": "2022-06-29T15:51:29.671407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_pickle(\"clean_data/final_data/df_principal.pkl\")\n",
    "\n",
    "rev1 = rev.loc[(rev['LABEL'] == 'TTM') | (rev['tipo_resultado'] == 'anual')]\n",
    "\n",
    "companies = rev1['CODIGO'].unique()\n",
    "\n",
    "grw = {}\n",
    "for x in companies:\n",
    "    try:\n",
    "        rev2 = rev1.loc[rev1['CODIGO'] == x].drop_duplicates(\"Crescimento Receita\")\n",
    "        growth = rev2['Crescimento Receita'][-5:].dropna().to_list()\n",
    "        growths = np.array(growth)\n",
    "        weights = []\n",
    "        for y in range(len(growths)):\n",
    "            weights.append(10**y)\n",
    "        growth_rate_mean = np.average(growths, weights=weights)\n",
    "        growth_rate_std_dev = growths.std()\n",
    "        grw[x] = growth_rate_mean\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:33.688291Z",
     "start_time": "2022-06-29T15:51:33.674436Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_crescimento_5anos = pd.DataFrame.from_dict(grw,orient='index',columns=['Média Crescimento Receitas 5 anos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:33.703503Z",
     "start_time": "2022-06-29T15:51:33.689290Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttm = ttm.merge(media_crescimento_5anos,right_index=True, left_on=['CODIGO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5-years average reinvested capital "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:37.426861Z",
     "start_time": "2022-06-29T15:51:33.705538Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_pickle(\"clean_data/final_data/df_principal.pkl\")\n",
    "\n",
    "rev1 = rev.loc[(rev['LABEL'] == 'TTM') | (rev['tipo_resultado'] == 'anual')]\n",
    "\n",
    "companies = rev1['CODIGO'].unique()\n",
    "\n",
    "pctr = {}\n",
    "for x in companies:\n",
    "    try:\n",
    "        rev2 = rev1.loc[rev1['CODIGO'] == x].drop_duplicates(\"Porcentagem Reinvestida\")\n",
    "        growth = rev2['Porcentagem Reinvestida'][-10:].dropna().to_list()\n",
    "        growth = [item for item in growth if item >= 0 and item < 1]\n",
    "        pctr_reinv = np.array(growth)\n",
    "        \n",
    "        media_porcent_reinv = np.average(pctr_reinv)\n",
    "\n",
    "        pctr[x] = media_porcent_reinv\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:37.442205Z",
     "start_time": "2022-06-29T15:51:37.428527Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "media_pctr_5anos = pd.DataFrame.from_dict(pctr,orient='index',columns=['Média Porcetagem Reivenstida 5 anos'])\n",
    "\n",
    "ttm = ttm.merge(media_pctr_5anos,right_index=True, left_on=['CODIGO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:37.473280Z",
     "start_time": "2022-06-29T15:51:37.444131Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "med = ttm.drop_duplicates('Nome_Empresarial',keep='first')\n",
    "\n",
    "mean = med.groupby('SEGMENTO')['Média Porcetagem Reivenstida 5 anos'].mean()\n",
    "\n",
    "ttm['Média Porcetagem Reivenstida 5 anos'] = np.select([ttm['Média Porcetagem Reivenstida 5 anos'].isna()],[mean[ttm['SEGMENTO']]],ttm['Média Porcetagem Reivenstida 5 anos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## CAGR Revenues 5-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:42.372708Z",
     "start_time": "2022-06-29T15:51:37.475311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_pickle(\"clean_data/final_data/df_principal.pkl\")\n",
    "\n",
    "rev1 = rev.loc[(rev['LABEL'] == 'TTM') | (rev['tipo_resultado'] == 'anual')]\n",
    "\n",
    "companies = rev1['CODIGO'].unique()\n",
    "\n",
    "cagr = {}\n",
    "for x in companies:\n",
    "    try:\n",
    "        rev2 = rev1.loc[rev1['CODIGO'] == x].drop_duplicates(\"Receita Líquida\")\n",
    "\n",
    "\n",
    "        rec = rev2[[\"LABEL\",\"Receita Líquida\"]][-6:].dropna()\n",
    "\n",
    "        first = rec.head(1)[\"Receita Líquida\"].item()\n",
    "        first_yr = rec.head(1)[\"LABEL\"].item()\n",
    "\n",
    "        last = rec.tail(1)[\"Receita Líquida\"].item()\n",
    "        last_yr = rec.tail(1)[\"LABEL\"].item()\n",
    "\n",
    "        num_yrs = int(last_year)-int(first_yr)\n",
    "\n",
    "        cagr_receita = np.power(last / first,(1 / num_yrs)) - 1\n",
    "\n",
    "        cagr[x] = cagr_receita\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:42.404508Z",
     "start_time": "2022-06-29T15:51:42.375722Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cagr_receita_5anos = pd.DataFrame.from_dict(cagr,orient='index',columns=['CAGR Receita 5 anos'])\n",
    "\n",
    "ttm = ttm.merge(cagr_receita_5anos,right_index=True, left_on=['CODIGO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## CAGR Earnings 5-years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.353194Z",
     "start_time": "2022-06-29T15:51:42.405515Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rev = pd.read_pickle(\"clean_data/final_data/df_principal.pkl\")\n",
    "\n",
    "rev1 = rev.loc[(rev['LABEL'] == 'TTM') | (rev['tipo_resultado'] == 'anual')]\n",
    "\n",
    "companies = rev1['CODIGO'].unique()\n",
    "\n",
    "cagr_lr = {}\n",
    "for x in companies:\n",
    "    try:\n",
    "        rev2 = rev1.loc[rev1['CODIGO'] == x].drop_duplicates(\"Lucro Líquido\")\n",
    "\n",
    "\n",
    "        rec = rev2[[\"LABEL\",\"Lucro Líquido\"]][-6:].dropna()\n",
    "\n",
    "        first = rec.head(1)[\"Lucro Líquido\"].item()\n",
    "        first_yr = rec.head(1)[\"LABEL\"].item()\n",
    "\n",
    "        last = rec.tail(1)[\"Lucro Líquido\"].item()\n",
    "        last_yr = rec.tail(1)[\"LABEL\"].item()\n",
    "\n",
    "        num_yrs = int(last_year)-int(first_yr)\n",
    "\n",
    "        cagr_lucro = np.power(last / first,(1 / num_yrs)) - 1\n",
    "\n",
    "        cagr_lr[x] = cagr_lucro\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.384769Z",
     "start_time": "2022-06-29T15:51:47.357204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cagr_lucro_5anos = pd.DataFrame.from_dict(cagr_lr,orient='index',columns=['CAGR Lucro 5 anos'])\n",
    "\n",
    "ttm = ttm.merge(cagr_lucro_5anos,right_index=True, left_on=['CODIGO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.416547Z",
     "start_time": "2022-06-29T15:51:47.385723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ttm.sort_values(['CLASSE_x'],inplace=True)\n",
    "\n",
    "ttm.drop_duplicates('Nome_Empresarial',keep='first',inplace=True)\n",
    "\n",
    "ttm.to_pickle('clean_data/final_data/last_results_alldata.pkl')\n",
    "\n",
    "##backup\n",
    "ttm.to_pickle('BACKUPS/last_results/last_results_alldata%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPIs averages calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.432080Z",
     "start_time": "2022-06-29T15:51:47.418463Z"
    }
   },
   "outputs": [],
   "source": [
    "last_results = pd.read_pickle('clean_data/final_data/last_results_alldata.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.447548Z",
     "start_time": "2022-06-29T15:51:47.434025Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "indicadores = ['Margem EBIT',\n",
    "             'Margem líquida',\n",
    "             'Margem bruta',\n",
    "             'Taxa efetiva de imposto',\n",
    "             'Dív_Líq/EBIT',\n",
    "             'Dív_Líq/PL',\n",
    "             'D/E',\n",
    "             'Dívida/Capital_Inv',\n",
    "             'Patrimônio/Capital_Inv',\n",
    "             'Endividamento Financeiro',\n",
    "             'Endividamento Financeiro Curto Prazo',\n",
    "             'Dív_Líq/ebitda',\n",
    "             'PL/Ativos',\n",
    "             'ROE',\n",
    "             'Porcentagem Retida',\n",
    "             'ROA',\n",
    "             'ROIC',\n",
    "             'Passivo/Ativo',\n",
    "             'Líquidez Corrente',\n",
    "             'Giro dos Ativos',\n",
    "             'Capital_Giro/revenues',\n",
    "             'Porcentagem Reinvestida',\n",
    "             'Receitas/Capital_Inv',\n",
    "             'Capex/Receita',\n",
    "             'Capex/Depreciação',\n",
    "             'Capex Líquido/Receita',\n",
    "             'Capex Líquido/EBIT(1-t)',\n",
    "             'Crescimento esperado LPA',\n",
    "             'Crescimento esperado EBIT',\n",
    "             'Crescimento EBIT',\n",
    "             'Crescimento Margem EBIT',\n",
    "             'Crescimento LPA',\n",
    "             'Crescimento Receita',\n",
    "             'LPA',\n",
    "             'VPA',\n",
    "             'P/L',\n",
    "             'P/VPA',\n",
    "             'P/EBITDA',\n",
    "             'P/EBIT',\n",
    "             'P/Ativo',\n",
    "             'P/Cap_Giro',\n",
    "             'P/Ativo_Circ_Líq',\n",
    "              'Payout','Dividend Yield','EV/EBIT','EV/EBITDA',\n",
    "              'beta','Média Crescimento Receitas 5 anos','Cost of Capital','Cost of Debt',\n",
    "              'IC ratio','Cost of Equity','CAGR Receita 5 anos','Média Porcetagem Reivenstida 5 anos',\n",
    "              'CAGR Lucro 5 anos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:47.463636Z",
     "start_time": "2022-06-29T15:51:47.449388Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    if len(df_in) > 5:   \n",
    "        q1 = df_in[col_name].quantile(0.15)\n",
    "        q3 = df_in[col_name].quantile(0.85)\n",
    "        iqr = q3-q1 #Interquartile range\n",
    "        fence_low  = q1-1.5*iqr\n",
    "        fence_high = q3+1.5*iqr\n",
    "        df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high) & (df_in[col_name] != 0)]\n",
    "        return df_out\n",
    "    else:\n",
    "        return df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:48.535761Z",
     "start_time": "2022-06-29T15:51:47.466645Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### calculating market average\n",
    "mean_indicators = last_results.drop(last_results.columns.difference(['CODIGO','SETOR',\n",
    "                                                                     'SEGMENTO','SUBSETOR',\n",
    "                                                                     'Classificação Capitalização',\n",
    "                                                                     'Margem EBITDA']),axis=1)\n",
    "mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "arq=remove_outlier(mean_indicators,'Margem EBITDA')\n",
    "\n",
    "for item in indicadores:\n",
    "    mean_indicators = last_results.drop(last_results.columns.difference(['CODIGO','SETOR',\n",
    "                                                                         'SEGMENTO','SUBSETOR',\n",
    "                                                                         'Classificação Capitalização',\n",
    "                                                                         item]),axis=1)\n",
    "    mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "    test = remove_outlier(mean_indicators,item)\n",
    "    arq = arq.merge(test,how='outer')\n",
    "\n",
    "medias_mercado_ttm = arq.mean()\n",
    "medias_mercado_ttm.name = 'Média Mercado'\n",
    "\n",
    "medias_mercado_ttm.to_pickle('clean_data/final_data/medias_mercado_ttm.pkl')\n",
    "medias_mercado_ttm.to_pickle('BACKUPS/medias/medias_mercado_ttm%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:48.551097Z",
     "start_time": "2022-06-29T15:51:48.537760Z"
    }
   },
   "outputs": [],
   "source": [
    "setores = last_results['SETOR'].unique()\n",
    "subsetores = last_results['SUBSETOR'].unique()\n",
    "segmento = last_results['SEGMENTO'].unique()\n",
    "capitaliz = last_results['Classificação Capitalização'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:51:55.364206Z",
     "start_time": "2022-06-29T15:51:48.553102Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### calculating sector averages\n",
    "concat_setor = pd.DataFrame()\n",
    "for setor in setores:\n",
    "    alq = last_results.loc[(last_results['SETOR'] == setor)]\n",
    "    mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                         'SEGMENTO','SUBSETOR',\n",
    "                                                                         'Classificação Capitalização',\n",
    "                                                                         'Margem EBITDA']),axis=1)\n",
    "    mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "    arq=remove_outlier(mean_indicators,'Margem EBITDA')\n",
    "\n",
    "    for item in indicadores:\n",
    "        mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                             'SEGMENTO','SUBSETOR',\n",
    "                                                                             'Classificação Capitalização',\n",
    "                                                                             item]),axis=1)\n",
    "        mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "        test = remove_outlier(mean_indicators,item)\n",
    "        arq = arq.merge(test,how='outer')\n",
    "        \n",
    "    concat_setor = pd.concat([concat_setor,arq])\n",
    "\n",
    "medias_setor = concat_setor.groupby('SETOR').mean()\n",
    "medias_setor.to_pickle('clean_data/final_data/medias_setor.pkl')\n",
    "medias_setor.to_pickle('BACKUPS/medias/medias_setor%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:52:18.949449Z",
     "start_time": "2022-06-29T15:51:55.366232Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### calculating subsector averages\n",
    "concat_subsetor = pd.DataFrame()\n",
    "for setor in subsetores:\n",
    "    alq = last_results.loc[(last_results['SUBSETOR'] == setor)]\n",
    "    mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                         'SEGMENTO','SUBSETOR',\n",
    "                                                                         'Classificação Capitalização',\n",
    "                                                                         'Margem EBITDA']),axis=1)\n",
    "    mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "    arq=remove_outlier(mean_indicators,'Margem EBITDA')\n",
    "\n",
    "    for item in indicadores:\n",
    "        mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                             'SEGMENTO','SUBSETOR',\n",
    "                                                                             'Classificação Capitalização',\n",
    "                                                                             item]),axis=1)\n",
    "        mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "        test = remove_outlier(mean_indicators,item)\n",
    "        arq = arq.merge(test,how='outer')\n",
    "        \n",
    "    concat_subsetor = pd.concat([concat_subsetor,arq])\n",
    "\n",
    "medias_subsetor = concat_subsetor.groupby('SUBSETOR').mean()\n",
    "medias_subsetor.to_pickle('clean_data/final_data/medias_subsetor.pkl')\n",
    "medias_subsetor.to_pickle('BACKUPS/medias/medias_subsetor%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:53:00.629055Z",
     "start_time": "2022-06-29T15:52:18.950946Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "### calculating industry averages\n",
    "concat_segmento = pd.DataFrame()\n",
    "for setor in segmento:\n",
    "    alq = last_results.loc[(last_results['SEGMENTO'] == setor)]\n",
    "    mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                         'SEGMENTO','SUBSETOR',\n",
    "                                                                         'Classificação Capitalização',\n",
    "                                                                         'Margem EBITDA']),axis=1)\n",
    "    mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "    arq=remove_outlier(mean_indicators,'Margem EBITDA')\n",
    "\n",
    "    for item in indicadores:\n",
    "        mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                             'SEGMENTO','SUBSETOR',\n",
    "                                                                             'Classificação Capitalização',\n",
    "                                                                             item]),axis=1)\n",
    "        mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "        test = remove_outlier(mean_indicators,item)\n",
    "        arq = arq.merge(test,how='outer')\n",
    "        \n",
    "    concat_segmento = pd.concat([concat_segmento,arq])\n",
    "\n",
    "medias_segmento = concat_segmento.groupby('SEGMENTO').mean()\n",
    "medias_segmento.to_pickle('clean_data/final_data/medias_segmento.pkl')\n",
    "medias_segmento.to_pickle('BACKUPS/medias/medias_segmento%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:53:05.042255Z",
     "start_time": "2022-06-29T15:53:00.630176Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### calculating capital segment averages\n",
    "concat_capital = pd.DataFrame()\n",
    "for setor in capitaliz:\n",
    "    alq = last_results.loc[(last_results['Classificação Capitalização'] == setor)]\n",
    "    mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                         'SEGMENTO','SUBSETOR',\n",
    "                                                                         'Classificação Capitalização',\n",
    "                                                                         'Margem EBITDA']),axis=1)\n",
    "    mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "    arq=remove_outlier(mean_indicators,'Margem EBITDA')\n",
    "\n",
    "    for item in indicadores:\n",
    "        mean_indicators = alq.drop(alq.columns.difference(['CODIGO','SETOR',\n",
    "                                                                             'SEGMENTO','SUBSETOR',\n",
    "                                                                             'Classificação Capitalização',\n",
    "                                                                             item]),axis=1)\n",
    "        mean_indicators.replace([-np.inf,np.inf],np.nan,inplace=True)\n",
    "\n",
    "        test = remove_outlier(mean_indicators,item)\n",
    "        arq = arq.merge(test,how='outer')\n",
    "        \n",
    "    concat_capital = pd.concat([concat_capital,arq])\n",
    "\n",
    "medias_capital = concat_capital.groupby('Classificação Capitalização').mean()\n",
    "medias_capital.to_pickle('clean_data/final_data/medias_capital.pkl')\n",
    "medias_capital.to_pickle('BACKUPS/medias/medias_capital%s.pkl'%today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SALES TO CAPITAL RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T15:53:05.105082Z",
     "start_time": "2022-06-29T15:53:05.044220Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## SCR do segmento no Brasil\n",
    "\n",
    "scmean = pd.read_pickle('clean_data/final_data/medias_segmento.pkl')\n",
    "\n",
    "scr_segmento_mean = scmean['Receitas/Capital_Inv']\n",
    "\n",
    "ttm['SCR segmento BR'] = np.nan\n",
    "ttm['SCR segmento BR'] = np.select([ttm['SCR segmento BR'].isna()],[scr_segmento_mean[ttm['SEGMENTO']]],\n",
    "                                  ttm['SCR segmento BR'])\n",
    "\n",
    "## SCR do setor no Brasil\n",
    "\n",
    "scmean_setor = pd.read_pickle('clean_data/final_data/medias_setor.pkl')\n",
    "\n",
    "scr_setor_mean = scmean_setor['Receitas/Capital_Inv']\n",
    "\n",
    "ttm['SCR setor BR'] = np.nan\n",
    "ttm['SCR setor BR'] = np.select([ttm['SCR setor BR'].isna()],[scr_setor_mean[ttm['SETOR']]],\n",
    "                                  ttm['SCR setor BR'])\n",
    "\n",
    "## SCR global\n",
    "\n",
    "scr_global = pd.read_excel(\"VALUATION/capexGlobal2021_damodaran.xlsx\")\n",
    "\n",
    "scr_global_mean = scr_global['Sales/Capital']\n",
    "\n",
    "ttm['SCR global'] = np.nan\n",
    "ttm['SCR global'] = np.select([ttm['SCR global'].isna()],[scr_global_mean[ttm['DAMODARAN_GROUP']]],\n",
    "                                  ttm['SCR global'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
