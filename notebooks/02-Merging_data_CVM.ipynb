{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:34:17.313633Z",
     "start_time": "2022-06-29T14:34:16.332524Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "this_year = datetime.datetime.today().strftime('%Y')\n",
    "today = datetime.datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Merging old data  with updated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:35:14.953496Z",
     "start_time": "2022-06-29T14:34:17.661560Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Getting ALL DFP'S FROM 2017 TO LAST YEAR AND CONCATING WITH 2010-2016\n",
    "nomes = ['BPA_con', 'BPA_ind', 'BPP_con', 'BPP_ind', 'DFC_MI_con', 'DFC_MI_ind', 'DRE_con', 'DRE_ind', 'DVA_con', 'DVA_ind', 'DFC_MD_con', 'DFC_MD_ind']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2017,int(this_year)):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/dfp/DFP/dfp_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    \n",
    "    arquivo['VL_CONTA'] = arquivo['VL_CONTA'].apply(lambda x: float(x))\n",
    "    hist_results = pd.read_pickle(f'merged_data_cvm/old_data/DFP/dfp_cia_aberta_{nome}_2010-2016.pkl')\n",
    "    all_res = pd.concat([hist_results,arquivo])\n",
    "    all_res.to_pickle(f'merged_data_cvm/new_data/DFP/dfp_cia_aberta_{nome}_tudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:35:39.096526Z",
     "start_time": "2022-06-29T14:35:14.958753Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Getting ALL DMPL ANNUAL FROM 2017 to TODAY and concating with 2010-2016\n",
    "nomes = ['DMPL_con','DMPL_ind']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2017,int(this_year)):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/dfp/DFP/dfp_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    \n",
    "    arquivo['COLUNA_DF'] =np.select([arquivo['COLUNA_DF'].isna()],['PL CON'],arquivo['COLUNA_DF'])\n",
    "    \n",
    "    dmplass = ['Patrimônio Líquido Consolidado','Participação dos Não Controladores','Patrimônio Líquido','Reservas de Lucro',\n",
    "          'Lucros ou Prejuízos Acumulados','PL CON']\n",
    "    arquivo = arquivo.query(\"COLUNA_DF == @dmplass\")\n",
    "    arquivo = arquivo.query(\"DS_CONTA == ['Saldos Iniciais','Saldos Finais']\")\n",
    "    arquivo['VL_CONTA'] = arquivo['VL_CONTA'].apply(lambda x: float(x))\n",
    "    \n",
    "    hist_results = pd.read_pickle(f'merged_data_cvm/old_data/DFP/dfp_cia_aberta_{nome}_2010-2016.pkl')\n",
    "    all_res = pd.concat([hist_results,arquivo])\n",
    "    all_res.to_pickle(f'merged_data_cvm/new_data/DFP/dfp_cia_aberta_{nome}_tudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:38:38.725190Z",
     "start_time": "2022-06-29T14:35:39.101075Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Getting ALL ITR'S FROM 2017 TO LAST YEAR AND CONCATING WITH 2011-2016\n",
    "nomes = ['BPA_con', 'BPA_ind', 'BPP_con', 'BPP_ind', 'DFC_MI_con', 'DFC_MI_ind', 'DRE_con', 'DRE_ind', 'DVA_con', 'DVA_ind', 'DFC_MD_con', 'DFC_MD_ind']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2017,int(this_year)+1):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/itr/ITR/itr_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    \n",
    "    arquivo['VL_CONTA'] = arquivo['VL_CONTA'].apply(lambda x: float(x))    \n",
    "    hist_results = pd.read_pickle(f'merged_data_cvm/old_data//ITR/itr_cia_aberta_{nome}_2011-2016.pkl')\n",
    "    all_res = pd.concat([hist_results,arquivo])\n",
    "    all_res.to_pickle(f'merged_data_cvm/new_data/ITR/itr_cia_aberta_{nome}_tudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:39:30.961987Z",
     "start_time": "2022-06-29T14:38:38.730898Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## GETTING ALL DMPL QUARTELY FROM 2017 TO today and concating with 2011-2016\n",
    "\n",
    "nomes = ['DMPL_con','DMPL_ind']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2017,int(this_year)+1):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/itr/ITR/itr_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    \n",
    "    arquivo['COLUNA_DF'] =np.select([arquivo['COLUNA_DF'].isna()],['PL CON'],arquivo['COLUNA_DF'])\n",
    "    \n",
    "    dmplass = ['Patrimônio Líquido Consolidado','Participação dos Não Controladores','Patrimônio Líquido','Reservas de Lucro',\n",
    "          'Lucros ou Prejuízos Acumulados','PL CON']\n",
    "    arquivo = arquivo.query(\"COLUNA_DF == @dmplass\")\n",
    "    arquivo = arquivo.query(\"DS_CONTA == ['Saldos Iniciais','Saldos Finais']\")   \n",
    "    \n",
    "    arquivo['VL_CONTA'] = arquivo['VL_CONTA'].apply(lambda x: float(x))\n",
    "    hist_results = pd.read_pickle(f'merged_data_cvm/old_data/ITR/itr_cia_aberta_{nome}_2011-2016.pkl')\n",
    "    all_res = pd.concat([hist_results,arquivo])\n",
    "    all_res.to_pickle(f'merged_data_cvm/new_data/ITR/itr_cia_aberta_{nome}_tudo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:39:36.283189Z",
     "start_time": "2022-06-29T14:39:30.963908Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Getting ALL FRE'S FROM 2010 TO 2021\n",
    "nomes = ['posicao_acionaria','distribuicao_capital']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2010,int(this_year)+1):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/fre/FRE/fre_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    arquivo.to_pickle(f'merged_data_cvm/new_data/FRE/fre_cia_aberta_{nome}_tudo.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:39:37.382799Z",
     "start_time": "2022-06-29T14:39:36.289116Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Getting ALL FCA'S FROM 2010 TO 2021\n",
    "nomes = ['geral']\n",
    "for nome in nomes:\n",
    "    arquivo = pd.DataFrame()\n",
    "    for ano in range(2010,int(this_year)+1):\n",
    "        arquivo = pd.concat([arquivo, pd.read_csv(f'raw_data_cvm/fca/FCA/fca_cia_aberta_{nome}_{ano}.csv', sep=';', decimal=',', encoding='ISO-8859-1')])\n",
    "    arquivo.to_pickle(f'merged_data_cvm/new_data/FCA/fca_cia_aberta_{nome}_tudo.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Creating dataframe with companies information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T14:39:38.226008Z",
     "start_time": "2022-06-29T14:39:37.384836Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## merging companies_data com FCA\n",
    "\n",
    "\n",
    "companies_data = pd.read_excel('info_brazilian_companies.xlsx')\n",
    "\n",
    "\n",
    "fca = pd.read_pickle('merged_data_cvm/new_data/FCA/fca_cia_aberta_geral_tudo.pkl')\n",
    "fca['Data_Referencia'] = pd.to_datetime(fca['Data_Referencia'])\n",
    "fca = fca.sort_values('Data_Referencia').drop_duplicates('Codigo_CVM',keep='last')\n",
    "fca['Codigo_CVM'] = fca['Codigo_CVM'].astype(np.int64)\n",
    "\n",
    "info_all = fca.merge(companies_data, left_on='Codigo_CVM', right_on='CD_CVM', how='inner')\n",
    "\n",
    "\n",
    "info_all.to_pickle('clean_data/info_companies/info_companies_geral_comSetor.pkl')\n",
    "\n",
    "##backup\n",
    "\n",
    "info_all.to_pickle('BACKUPS/info_companies/info_companies_geral_comSetor%s.pkl'%today)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
